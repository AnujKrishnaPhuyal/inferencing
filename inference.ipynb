{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a06d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0c8b50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[755, 11294, 7, 264, 11, 293, 8]\n",
      "   755 → 'def'\n",
      " 11294 → ' calculate'\n",
      "     7 → '('\n",
      "   264 → ' a'\n",
      "    11 → ','\n",
      "   293 → ' b'\n",
      "     8 → ')'\n",
      "  7 tokens in line: 'def calculate( a, b)'\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "code = \"def calculate( a, b)\"\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")  # cl100k_base\n",
    "# enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokens = enc.encode(code)\n",
    "\n",
    "print(tokens)\n",
    "# Output: [285, 13913, 1389, 3058, 7, 64, 11, 570, 29, 25, 198, 220, 220, 220, 220, 892, 64, 610, 65]\n",
    "\n",
    "for token in enc.encode(code):\n",
    "    print(f\"{token:6} → {repr(enc.decode([token]))}\")\n",
    "\n",
    "for line in code.split(\"\\n\"):\n",
    "    line_tokens = enc.encode(line)\n",
    "    print(f\"{len(line_tokens):3} tokens in line: {repr(line)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b86be8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return\n",
      " a\n",
      " +\n",
      " b\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import math\n",
    "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "payload = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": code}],\n",
    "    \"max_tokens\": 0,\n",
    "    \"logprobs\": True,\n",
    "    \"top_logprobs\": 1\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    url,\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json=payload\n",
    ")\n",
    "response.raise_for_status()\n",
    "data = response.json()\n",
    "\n",
    "a = data[\"choices\"][0][\"logprobs\"][\"content\"]\n",
    "for item in a:\n",
    "    print(item['token'])\n",
    "# \"def calculate( a, b)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c261a4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'token': ':',\n",
       "  'bytes': [58],\n",
       "  'logprob': -3.3880937,\n",
       "  'top_logprobs': [{'token': '   ',\n",
       "    'bytes': [32, 32, 32],\n",
       "    'logprob': -0.98145264}]},\n",
       " {'token': ' \\n',\n",
       "  'bytes': [32, 10],\n",
       "  'logprob': -0.012783682,\n",
       "  'top_logprobs': [{'token': ' \\n',\n",
       "    'bytes': [32, 10],\n",
       "    'logprob': -0.012783682}]},\n",
       " {'token': '   ',\n",
       "  'bytes': [32, 32, 32],\n",
       "  'logprob': -0.06824574,\n",
       "  'top_logprobs': [{'token': '   ',\n",
       "    'bytes': [32, 32, 32],\n",
       "    'logprob': -0.06824574}]},\n",
       " {'token': ' sum',\n",
       "  'bytes': [32, 115, 117, 109],\n",
       "  'logprob': -0.4544645,\n",
       "  'top_logprobs': [{'token': ' sum',\n",
       "    'bytes': [32, 115, 117, 109],\n",
       "    'logprob': -0.4544645}]},\n",
       " {'token': ' =',\n",
       "  'bytes': [32, 61],\n",
       "  'logprob': -0.01865343,\n",
       "  'top_logprobs': [{'token': ' =',\n",
       "    'bytes': [32, 61],\n",
       "    'logprob': -0.01865343}]},\n",
       " {'token': ' a',\n",
       "  'bytes': [32, 97],\n",
       "  'logprob': -6.587483e-05,\n",
       "  'top_logprobs': [{'token': ' a',\n",
       "    'bytes': [32, 97],\n",
       "    'logprob': -6.587483e-05}]},\n",
       " {'token': ' +',\n",
       "  'bytes': [32, 43],\n",
       "  'logprob': -6.46828e-05,\n",
       "  'top_logprobs': [{'token': ' +',\n",
       "    'bytes': [32, 43],\n",
       "    'logprob': -6.46828e-05}]},\n",
       " {'token': ' b',\n",
       "  'bytes': [32, 98],\n",
       "  'logprob': -1.6166903e-05,\n",
       "  'top_logprobs': [{'token': ' b',\n",
       "    'bytes': [32, 98],\n",
       "    'logprob': -1.6166903e-05}]},\n",
       " {'token': '\\n',\n",
       "  'bytes': [10],\n",
       "  'logprob': -0.010644171,\n",
       "  'top_logprobs': [{'token': '\\n', 'bytes': [10], 'logprob': -0.010644171}]},\n",
       " {'token': '   ',\n",
       "  'bytes': [32, 32, 32],\n",
       "  'logprob': -2.1054253e-05,\n",
       "  'top_logprobs': [{'token': '   ',\n",
       "    'bytes': [32, 32, 32],\n",
       "    'logprob': -2.1054253e-05}]},\n",
       " {'token': ' difference',\n",
       "  'bytes': [32, 100, 105, 102, 102, 101, 114, 101, 110, 99, 101],\n",
       "  'logprob': -0.0040786397,\n",
       "  'top_logprobs': [{'token': ' difference',\n",
       "    'bytes': [32, 100, 105, 102, 102, 101, 114, 101, 110, 99, 101],\n",
       "    'logprob': -0.0040786397}]},\n",
       " {'token': ' =',\n",
       "  'bytes': [32, 61],\n",
       "  'logprob': -4.1318875e-05,\n",
       "  'top_logprobs': [{'token': ' =',\n",
       "    'bytes': [32, 61],\n",
       "    'logprob': -4.1318875e-05}]},\n",
       " {'token': ' a',\n",
       "  'bytes': [32, 97],\n",
       "  'logprob': -0.0025680452,\n",
       "  'top_logprobs': [{'token': ' a',\n",
       "    'bytes': [32, 97],\n",
       "    'logprob': -0.0025680452}]},\n",
       " {'token': ' -',\n",
       "  'bytes': [32, 45],\n",
       "  'logprob': -6.6306106e-06,\n",
       "  'top_logprobs': [{'token': ' -',\n",
       "    'bytes': [32, 45],\n",
       "    'logprob': -6.6306106e-06}]},\n",
       " {'token': ' b',\n",
       "  'bytes': [32, 98],\n",
       "  'logprob': -6.754368e-05,\n",
       "  'top_logprobs': [{'token': ' b',\n",
       "    'bytes': [32, 98],\n",
       "    'logprob': -6.754368e-05}]},\n",
       " {'token': '\\n',\n",
       "  'bytes': [10],\n",
       "  'logprob': -0.0007460217,\n",
       "  'top_logprobs': [{'token': '\\n', 'bytes': [10], 'logprob': -0.0007460217}]},\n",
       " {'token': '   ',\n",
       "  'bytes': [32, 32, 32],\n",
       "  'logprob': -4.1273333e-06,\n",
       "  'top_logprobs': [{'token': '   ',\n",
       "    'bytes': [32, 32, 32],\n",
       "    'logprob': -4.1273333e-06}]},\n",
       " {'token': ' product',\n",
       "  'bytes': [32, 112, 114, 111, 100, 117, 99, 116],\n",
       "  'logprob': -0.0003246183,\n",
       "  'top_logprobs': [{'token': ' product',\n",
       "    'bytes': [32, 112, 114, 111, 100, 117, 99, 116],\n",
       "    'logprob': -0.0003246183}]},\n",
       " {'token': ' =',\n",
       "  'bytes': [32, 61],\n",
       "  'logprob': -6.921253e-05,\n",
       "  'top_logprobs': [{'token': ' =',\n",
       "    'bytes': [32, 61],\n",
       "    'logprob': -6.921253e-05}]},\n",
       " {'token': ' a',\n",
       "  'bytes': [32, 97],\n",
       "  'logprob': -2.0458236e-05,\n",
       "  'top_logprobs': [{'token': ' a',\n",
       "    'bytes': [32, 97],\n",
       "    'logprob': -2.0458236e-05}]},\n",
       " {'token': ' *',\n",
       "  'bytes': [32, 42],\n",
       "  'logprob': -0.00010735771,\n",
       "  'top_logprobs': [{'token': ' *',\n",
       "    'bytes': [32, 42],\n",
       "    'logprob': -0.00010735771}]},\n",
       " {'token': ' b',\n",
       "  'bytes': [32, 98],\n",
       "  'logprob': -2.3795938e-05,\n",
       "  'top_logprobs': [{'token': ' b',\n",
       "    'bytes': [32, 98],\n",
       "    'logprob': -2.3795938e-05}]},\n",
       " {'token': '\\n',\n",
       "  'bytes': [10],\n",
       "  'logprob': -0.0013615437,\n",
       "  'top_logprobs': [{'token': '\\n', 'bytes': [10], 'logprob': -0.0013615437}]},\n",
       " {'token': '   ',\n",
       "  'bytes': [32, 32, 32],\n",
       "  'logprob': -4.723352e-06,\n",
       "  'top_logprobs': [{'token': '   ',\n",
       "    'bytes': [32, 32, 32],\n",
       "    'logprob': -4.723352e-06}]},\n",
       " {'token': ' quotient',\n",
       "  'bytes': [32, 113, 117, 111, 116, 105, 101, 110, 116],\n",
       "  'logprob': -0.15214585,\n",
       "  'top_logprobs': [{'token': ' quotient',\n",
       "    'bytes': [32, 113, 117, 111, 116, 105, 101, 110, 116],\n",
       "    'logprob': -0.15214585}]},\n",
       " {'token': ' =',\n",
       "  'bytes': [32, 61],\n",
       "  'logprob': -2.8921695e-05,\n",
       "  'top_logprobs': [{'token': ' =',\n",
       "    'bytes': [32, 61],\n",
       "    'logprob': -2.8921695e-05}]},\n",
       " {'token': ' a',\n",
       "  'bytes': [32, 97],\n",
       "  'logprob': -0.0037480602,\n",
       "  'top_logprobs': [{'token': ' a',\n",
       "    'bytes': [32, 97],\n",
       "    'logprob': -0.0037480602}]},\n",
       " {'token': ' /',\n",
       "  'bytes': [32, 47],\n",
       "  'logprob': -0.0005712636,\n",
       "  'top_logprobs': [{'token': ' /',\n",
       "    'bytes': [32, 47],\n",
       "    'logprob': -0.0005712636}]},\n",
       " {'token': ' b',\n",
       "  'bytes': [32, 98],\n",
       "  'logprob': -4.429897e-05,\n",
       "  'top_logprobs': [{'token': ' b',\n",
       "    'bytes': [32, 98],\n",
       "    'logprob': -4.429897e-05}]},\n",
       " {'token': '\\n    \\n',\n",
       "  'bytes': [10, 32, 32, 32, 32, 10],\n",
       "  'logprob': -0.32460618,\n",
       "  'top_logprobs': [{'token': '\\n    \\n',\n",
       "    'bytes': [10, 32, 32, 32, 32, 10],\n",
       "    'logprob': -0.32460618}]},\n",
       " {'token': '   ',\n",
       "  'bytes': [32, 32, 32],\n",
       "  'logprob': -3.297462e-05,\n",
       "  'top_logprobs': [{'token': '   ',\n",
       "    'bytes': [32, 32, 32],\n",
       "    'logprob': -3.297462e-05}]},\n",
       " {'token': ' return',\n",
       "  'bytes': [32, 114, 101, 116, 117, 114, 110],\n",
       "  'logprob': -0.0062593734,\n",
       "  'top_logprobs': [{'token': ' return',\n",
       "    'bytes': [32, 114, 101, 116, 117, 114, 110],\n",
       "    'logprob': -0.0062593734}]},\n",
       " {'token': ' sum',\n",
       "  'bytes': [32, 115, 117, 109],\n",
       "  'logprob': -0.023255378,\n",
       "  'top_logprobs': [{'token': ' sum',\n",
       "    'bytes': [32, 115, 117, 109],\n",
       "    'logprob': -0.023255378}]},\n",
       " {'token': ',',\n",
       "  'bytes': [44],\n",
       "  'logprob': -2.4272753e-05,\n",
       "  'top_logprobs': [{'token': ',', 'bytes': [44], 'logprob': -2.4272753e-05}]},\n",
       " {'token': ' difference',\n",
       "  'bytes': [32, 100, 105, 102, 102, 101, 114, 101, 110, 99, 101],\n",
       "  'logprob': -5.5122365e-07,\n",
       "  'top_logprobs': [{'token': ' difference',\n",
       "    'bytes': [32, 100, 105, 102, 102, 101, 114, 101, 110, 99, 101],\n",
       "    'logprob': -5.5122365e-07}]},\n",
       " {'token': ',',\n",
       "  'bytes': [44],\n",
       "  'logprob': -6.704273e-07,\n",
       "  'top_logprobs': [{'token': ',', 'bytes': [44], 'logprob': -6.704273e-07}]},\n",
       " {'token': ' product',\n",
       "  'bytes': [32, 112, 114, 111, 100, 117, 99, 116],\n",
       "  'logprob': -4.604148e-06,\n",
       "  'top_logprobs': [{'token': ' product',\n",
       "    'bytes': [32, 112, 114, 111, 100, 117, 99, 116],\n",
       "    'logprob': -4.604148e-06}]},\n",
       " {'token': ',',\n",
       "  'bytes': [44],\n",
       "  'logprob': -2.220075e-06,\n",
       "  'top_logprobs': [{'token': ',', 'bytes': [44], 'logprob': -2.220075e-06}]},\n",
       " {'token': ' quotient',\n",
       "  'bytes': [32, 113, 117, 111, 116, 105, 101, 110, 116],\n",
       "  'logprob': -4.5371802e-05,\n",
       "  'top_logprobs': [{'token': ' quotient',\n",
       "    'bytes': [32, 113, 117, 111, 116, 105, 101, 110, 116],\n",
       "    'logprob': -4.5371802e-05}]}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = data[\"choices\"][0][\"logprobs\"][\"content\"]\n",
    "content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa14f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\MachineLearning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c31a1a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at Salesforce/codegen-350M-mono were not used when initializing CodeGenForCausalLM: ['transformer.h.0.attn.causal_mask', 'transformer.h.1.attn.causal_mask', 'transformer.h.10.attn.causal_mask', 'transformer.h.11.attn.causal_mask', 'transformer.h.12.attn.causal_mask', 'transformer.h.13.attn.causal_mask', 'transformer.h.14.attn.causal_mask', 'transformer.h.15.attn.causal_mask', 'transformer.h.16.attn.causal_mask', 'transformer.h.17.attn.causal_mask', 'transformer.h.18.attn.causal_mask', 'transformer.h.19.attn.causal_mask', 'transformer.h.2.attn.causal_mask', 'transformer.h.3.attn.causal_mask', 'transformer.h.4.attn.causal_mask', 'transformer.h.5.attn.causal_mask', 'transformer.h.6.attn.causal_mask', 'transformer.h.7.attn.causal_mask', 'transformer.h.8.attn.causal_mask', 'transformer.h.9.attn.causal_mask']\n",
      "- This IS expected if you are initializing CodeGenForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CodeGenForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CodeGenForCausalLM(\n",
       "  (transformer): CodeGenModel(\n",
       "    (wte): Embedding(51200, 1024)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-19): 20 x CodeGenBlock(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-mono\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f4954b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLEANED CODE ===\n",
      "\n",
      "utf-8\n",
      "def insertion_sort(arr):\n",
      "\n",
      "    for i in range(1, len(arr)):\n",
      "\n",
      "        key = arr[i]\n",
      "\n",
      "j = i - 1\n",
      "\n",
      "while j >= 0 and arr[j] > key:\n",
      "\n",
      "            arr[j + 1] = arr[j]\n",
      "\n",
      "j -= 1\n",
      "\n",
      "arr[j + 1] = key\n",
      "\n",
      "return arr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tokenize\n",
    "import sys\n",
    "from io import BytesIO\n",
    "\n",
    "def remove_comments(source_code):\n",
    "    \"\"\"\n",
    "    Removes all comments and docstrings from Python source code.\n",
    "    Preserves string literals and code logic.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    prev_toktype = tokenize.INDENT\n",
    "    last_lineno = -1\n",
    "    last_col = 0\n",
    "\n",
    "    try:\n",
    "        tokens = tokenize.tokenize(BytesIO(source_code.encode('utf-8')).readline)\n",
    "    except IndentationError:\n",
    "        # Fallback: simple line-by-line removal if tokenize fails\n",
    "        return remove_comments_fallback(source_code)\n",
    "\n",
    "    for tok in tokens:\n",
    "        toktype, tokstring, (srow, scol), (erow, ecol), line = tok\n",
    "        \n",
    "        # Skip comment tokens\n",
    "        if toktype == tokenize.COMMENT:\n",
    "            continue\n",
    "            \n",
    "        # Skip entire docstring (triple-quoted strings at module/class/function level)\n",
    "        if (toktype == tokenize.STRING and \n",
    "            tokstring.startswith('\"\"\"') or tokstring.startswith(\"'''\")):\n",
    "            # Only remove if it's a docstring (at indentation level 0 of its block)\n",
    "            if prev_toktype in (tokenize.INDENT, tokenize.NEWLINE) or prev_toktype == tokenize.INDENT:\n",
    "                if scol == last_col:  # Same indentation → likely docstring\n",
    "                    continue\n",
    "\n",
    "        # Preserve everything else\n",
    "        if last_lineno != srow:\n",
    "            # Add newline only if we skipped lines\n",
    "            if last_lineno != -1:\n",
    "                result.append('\\n')\n",
    "            last_col = 0\n",
    "        elif scol > last_col:\n",
    "            result.append(' ' * (scol - last_col))\n",
    "\n",
    "        result.append(tokstring)\n",
    "        last_col = ecol\n",
    "        last_lineno = erow\n",
    "        prev_toktype = toktype\n",
    "\n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "def remove_comments_fallback(source_code):\n",
    "    \"\"\"Fallback: remove # comments only (if tokenize fails)\"\"\"\n",
    "    lines = source_code.splitlines()\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        # Remove trailing comments\n",
    "        if '#' in line:\n",
    "            line = line.split('#', 1)[0].rstrip()\n",
    "        cleaned.append(line)\n",
    "    return '\\n'.join(cleaned) + '\\n'\n",
    "\n",
    "\n",
    "# === USAGE EXAMPLE ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Read from file or use sample\n",
    "    if len(sys.argv) > 1:\n",
    "        filepath = r\"C:\\Users\\MSI\\Downloads\\inferencing\\code.py\"\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            code = f.read()\n",
    "    else:\n",
    "        # Sample code with all kinds of comments\n",
    "        code =  \"\"\"def insertion_sort(arr):\n",
    "    for i in range(1, len(arr)):\n",
    "        key = arr[i]\n",
    "        j = i - 1\n",
    "        while j >= 0 and arr[j] > key:\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j + 1] = key\n",
    "    return arr\n",
    "\"\"\"\n",
    "\n",
    "    clean_code = remove_comments(code)\n",
    "    print(\"=== CLEANED CODE ===\\n\")\n",
    "    print(clean_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86b0bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"def insertion_sort(arr):\n",
    "    for i in range(1, len(arr)):\n",
    "        key = arr[i]\n",
    "        j = i - 1\n",
    "        while j >= 0 and arr[j] > key:\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j + 1] = key\n",
    "    return arr\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4544470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Your code here\n",
    "# code = \"\"\"\n",
    "# def add_nums(a, b):\n",
    "#     return a + b\n",
    "# \"\"\"\n",
    "\n",
    "# Tokenize once\n",
    "tokens = tokenizer(code, return_tensors=\"pt\")\n",
    "input_ids = tokens.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c14299cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4299 → 'def'\n",
      "36075 → ' insertion'\n",
      "62 → '_'\n",
      "30619 → 'sort'\n",
      "7 → '('\n",
      "3258 → 'arr'\n",
      "2599 → '):'\n",
      "198 → '\\n'\n",
      "50284 → '    '\n",
      "1640 → 'for'\n",
      "1312 → ' i'\n",
      "287 → ' in'\n",
      "2837 → ' range'\n",
      "7 → '('\n",
      "16 → '1'\n",
      "11 → ','\n",
      "18896 → ' len'\n",
      "7 → '('\n",
      "3258 → 'arr'\n",
      "8 → ')'\n",
      "2599 → '):'\n",
      "198 → '\\n'\n",
      "50280 → '        '\n",
      "2539 → 'key'\n",
      "796 → ' ='\n",
      "5240 → ' arr'\n",
      "58 → '['\n",
      "72 → 'i'\n",
      "60 → ']'\n",
      "198 → '\\n'\n",
      "50280 → '        '\n",
      "73 → 'j'\n",
      "796 → ' ='\n",
      "1312 → ' i'\n",
      "532 → ' -'\n",
      "352 → ' 1'\n",
      "198 → '\\n'\n",
      "50280 → '        '\n",
      "4514 → 'while'\n",
      "474 → ' j'\n",
      "18189 → ' >='\n",
      "657 → ' 0'\n",
      "290 → ' and'\n",
      "5240 → ' arr'\n",
      "58 → '['\n",
      "73 → 'j'\n",
      "60 → ']'\n",
      "1875 → ' >'\n",
      "1994 → ' key'\n",
      "25 → ':'\n",
      "198 → '\\n'\n",
      "50276 → '            '\n",
      "3258 → 'arr'\n",
      "58 → '['\n",
      "73 → 'j'\n",
      "1343 → ' +'\n",
      "352 → ' 1'\n",
      "60 → ']'\n",
      "796 → ' ='\n",
      "5240 → ' arr'\n",
      "58 → '['\n",
      "73 → 'j'\n",
      "60 → ']'\n",
      "198 → '\\n'\n",
      "50276 → '            '\n",
      "73 → 'j'\n",
      "48185 → ' -='\n",
      "352 → ' 1'\n",
      "198 → '\\n'\n",
      "50280 → '        '\n",
      "3258 → 'arr'\n",
      "58 → '['\n",
      "73 → 'j'\n",
      "1343 → ' +'\n",
      "352 → ' 1'\n",
      "60 → ']'\n",
      "796 → ' ='\n",
      "1994 → ' key'\n",
      "198 → '\\n'\n",
      "50284 → '    '\n",
      "7783 → 'return'\n",
      "5240 → ' arr'\n",
      "198 → '\\n'\n"
     ]
    }
   ],
   "source": [
    "a = tokenizer.decode(input_ids[0])\n",
    "for token_id in input_ids[0]:\n",
    "    print(token_id.item(), '→', repr(tokenizer.decode([token_id.item()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4594112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_token(token_id):\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Shift: logits[i] predicts token i+1\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    shift_labels = input_ids[..., 1:].contiguous()\n",
    "\n",
    "    # Prob of the actual next token\n",
    "    probs = torch.softmax(shift_logits, dim=-1)\n",
    "    actual_probs = torch.gather(probs, 2, shift_labels.unsqueeze(-1)).squeeze(-1)\n",
    "    return actual_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3fa5320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>token</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>insertion</td>\n",
       "      <td>2.5789729988900945e-05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>_</td>\n",
       "      <td>0.5008121132850647%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>sort</td>\n",
       "      <td>0.9590533971786499%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>(</td>\n",
       "      <td>0.9497361183166504%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>arr</td>\n",
       "      <td>0.1397678256034851%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td></td>\n",
       "      <td>0.801405131816864%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td></td>\n",
       "      <td>0.25840744376182556%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>return</td>\n",
       "      <td>0.9198158383369446%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>arr</td>\n",
       "      <td>0.9973148703575134%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td></td>\n",
       "      <td>0.45400211215019226%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pos      token                     prob\n",
       "0     1  insertion  2.5789729988900945e-05%\n",
       "1     2          _      0.5008121132850647%\n",
       "2     3       sort      0.9590533971786499%\n",
       "3     4          (      0.9497361183166504%\n",
       "4     5        arr      0.1397678256034851%\n",
       "..  ...        ...                      ...\n",
       "77   78                  0.801405131816864%\n",
       "78   79                0.25840744376182556%\n",
       "79   80     return      0.9198158383369446%\n",
       "80   81        arr      0.9973148703575134%\n",
       "81   82                0.45400211215019226%\n",
       "\n",
       "[82 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_probs_long(code, stride=512, max_len=2048):\n",
    "    tokens = tokenizer(code, return_tensors=\"pt\").input_ids[0]\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0, len(tokens), stride):\n",
    "        window = tokens[i:i+max_len]\n",
    "        if len(window) < 2: break\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            out = model(window.unsqueeze(0), labels=window.unsqueeze(0))\n",
    "            probs = torch.softmax(out.logits[0, :-1], dim=-1)\n",
    "            actual = window[1:]\n",
    "            prob = torch.gather(probs, 1, actual.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        start = max(i, 0)\n",
    "        for j, (tok_id, p) in enumerate(zip(actual, prob)):\n",
    "            token = tokenizer.decode(tok_id)\n",
    "            results.append({\n",
    "                \"pos\": start + j + 1,\n",
    "                \"token\": token.strip(),\n",
    "                \"prob\": f\"{p.item()}%\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "data_frame = token_probs_long(code)\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8dcf783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "  0 tokens in line: \n",
      " 10 tokens in line: def add_nums(a, b):\n",
      "  5 tokens in line:     return a + b\n",
      "  0 tokens in line: \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(len(data_frame)), [float(p[:-1]) for p in data_frame['prob']])\n",
    "plt.title(\"Estimated probability at each token?\")\n",
    "plt.ylabel(\"Probability %\")\n",
    "plt.show()\n",
    "data_frame\n",
    "\n",
    "print(len(data_frame))\n",
    "for line in code.split(\"\\n\"):\n",
    "    line_tokens = tokenizer.encode(line)\n",
    "    print(f\"{len(line_tokens):3} tokens in line: {tokenizer.decode(line_tokens)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f4abeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
